Lip Motion to Text Conversion
This project aims to interpret lip movements and generate corresponding text solely based on lip motion. It has been implemented using two distinct methods:

Method 1: Geometric Approach
Lip sequences are analyzed geometrically and converted into text. This approach is based on my own research, utilizing a custom dataset that I personally created. The implementation details can be found in project.ipynb.

Method 2: Deep Learning-Based Sentence Interpretation
This method leverages deep learning to interpret full sentences from lip movements. The GRIP Corpus Dataset is used for training and evaluation. The corresponding implementation is documented in lip_reading_sentences.ipynb.

A high-level overview of this project is available in 3rd_Sem_Presentation_Md_Laraib_Ahmad.pdf
